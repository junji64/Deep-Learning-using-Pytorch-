{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss graph\n",
    "\n",
    "$ \\text{loss}(w) = { 1 \\over N} \\sum^{N}_{n=1} (\\hat{y_n}-y_n)^2 = { 1 \\over N} \\sum^{N}_{n=1} (w*x_n - y_n)^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the learning => find w that minimizes the loss\n",
    "\n",
    "$ {\\min}_w  \\text{loss}(w) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent algorithm\n",
    "\n",
    "\n",
    "$$ \\text{Gradient} \\Rightarrow { \\partial \\text{loss} \\over \\partial w } $$\n",
    "\n",
    "$$ w = w - \\alpha {\\partial \\text{loss} \\over \\partial w} $$ \n",
    "\n",
    "$$ \\text{loss} = (\\hat{y} - y) ^2 = (w*x -y)^2  $$\n",
    "\n",
    "$$ {\\partial \\text{loss} \\over \\partial w} = 2x(w*x - y)  $$\n",
    "\n",
    "$$ w = w - \\alpha * 2 * x (w*x - y)  $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t grad: 1 2 -2.0\n",
      "\t grad: 2 4 -7.84\n",
      "\t grad: 3 6 -16.2288\n",
      "progress: 0 w = 1.26 loss = 4.91924\n",
      "\t grad: 1 2 -1.478624\n",
      "\t grad: 2 4 -5.796206\n",
      "\t grad: 3 6 -11.998147\n",
      "\t grad: 1 2 -1.093164\n",
      "\t grad: 2 4 -4.285205\n",
      "\t grad: 3 6 -8.870374\n",
      "\t grad: 1 2 -0.80819\n",
      "\t grad: 2 4 -3.168103\n",
      "\t grad: 3 6 -6.557974\n",
      "\t grad: 1 2 -0.597504\n",
      "\t grad: 2 4 -2.342217\n",
      "\t grad: 3 6 -4.848389\n",
      "\t grad: 1 2 -0.441742\n",
      "\t grad: 2 4 -1.731629\n",
      "\t grad: 3 6 -3.584472\n",
      "\t grad: 1 2 -0.326585\n",
      "\t grad: 2 4 -1.280214\n",
      "\t grad: 3 6 -2.650043\n",
      "\t grad: 1 2 -0.241448\n",
      "\t grad: 2 4 -0.946478\n",
      "\t grad: 3 6 -1.959209\n",
      "\t grad: 1 2 -0.178506\n",
      "\t grad: 2 4 -0.699742\n",
      "\t grad: 3 6 -1.448466\n",
      "\t grad: 1 2 -0.131971\n",
      "\t grad: 2 4 -0.517328\n",
      "\t grad: 3 6 -1.070869\n",
      "\t grad: 1 2 -0.097568\n",
      "\t grad: 2 4 -0.382467\n",
      "\t grad: 3 6 -0.791706\n",
      "progress: 10 w = 1.96 loss = 0.011707\n",
      "\t grad: 1 2 -0.072133\n",
      "\t grad: 2 4 -0.282762\n",
      "\t grad: 3 6 -0.585318\n",
      "\t grad: 1 2 -0.053329\n",
      "\t grad: 2 4 -0.209049\n",
      "\t grad: 3 6 -0.432732\n",
      "\t grad: 1 2 -0.039427\n",
      "\t grad: 2 4 -0.154553\n",
      "\t grad: 3 6 -0.319924\n",
      "\t grad: 1 2 -0.029149\n",
      "\t grad: 2 4 -0.114263\n",
      "\t grad: 3 6 -0.236524\n",
      "\t grad: 1 2 -0.02155\n",
      "\t grad: 2 4 -0.084476\n",
      "\t grad: 3 6 -0.174865\n",
      "\t grad: 1 2 -0.015932\n",
      "\t grad: 2 4 -0.062454\n",
      "\t grad: 3 6 -0.12928\n",
      "\t grad: 1 2 -0.011779\n",
      "\t grad: 2 4 -0.046173\n",
      "\t grad: 3 6 -0.095578\n",
      "\t grad: 1 2 -0.008708\n",
      "\t grad: 2 4 -0.034136\n",
      "\t grad: 3 6 -0.070662\n",
      "\t grad: 1 2 -0.006438\n",
      "\t grad: 2 4 -0.025237\n",
      "\t grad: 3 6 -0.052241\n",
      "\t grad: 1 2 -0.00476\n",
      "\t grad: 2 4 -0.018658\n",
      "\t grad: 3 6 -0.038623\n",
      "progress: 20 w = 2.0 loss = 2.8e-05\n",
      "\t grad: 1 2 -0.003519\n",
      "\t grad: 2 4 -0.013794\n",
      "\t grad: 3 6 -0.028554\n",
      "\t grad: 1 2 -0.002602\n",
      "\t grad: 2 4 -0.010198\n",
      "\t grad: 3 6 -0.02111\n",
      "\t grad: 1 2 -0.001923\n",
      "\t grad: 2 4 -0.00754\n",
      "\t grad: 3 6 -0.015607\n",
      "\t grad: 1 2 -0.001422\n",
      "\t grad: 2 4 -0.005574\n",
      "\t grad: 3 6 -0.011539\n",
      "\t grad: 1 2 -0.001051\n",
      "\t grad: 2 4 -0.004121\n",
      "\t grad: 3 6 -0.008531\n",
      "\t grad: 1 2 -0.000777\n",
      "\t grad: 2 4 -0.003047\n",
      "\t grad: 3 6 -0.006307\n",
      "\t grad: 1 2 -0.000575\n",
      "\t grad: 2 4 -0.002253\n",
      "\t grad: 3 6 -0.004663\n",
      "\t grad: 1 2 -0.000425\n",
      "\t grad: 2 4 -0.001665\n",
      "\t grad: 3 6 -0.003447\n",
      "\t grad: 1 2 -0.000314\n",
      "\t grad: 2 4 -0.001231\n",
      "\t grad: 3 6 -0.002549\n",
      "\t grad: 1 2 -0.000232\n",
      "\t grad: 2 4 -0.00091\n",
      "\t grad: 3 6 -0.001884\n",
      "progress: 30 w = 2.0 loss = 0.0\n",
      "\t grad: 1 2 -0.000172\n",
      "\t grad: 2 4 -0.000673\n",
      "\t grad: 3 6 -0.001393\n",
      "\t grad: 1 2 -0.000127\n",
      "\t grad: 2 4 -0.000498\n",
      "\t grad: 3 6 -0.00103\n",
      "\t grad: 1 2 -9.4e-05\n",
      "\t grad: 2 4 -0.000368\n",
      "\t grad: 3 6 -0.000761\n",
      "\t grad: 1 2 -6.9e-05\n",
      "\t grad: 2 4 -0.000272\n",
      "\t grad: 3 6 -0.000563\n",
      "\t grad: 1 2 -5.1e-05\n",
      "\t grad: 2 4 -0.000201\n",
      "\t grad: 3 6 -0.000416\n",
      "\t grad: 1 2 -3.8e-05\n",
      "\t grad: 2 4 -0.000149\n",
      "\t grad: 3 6 -0.000308\n",
      "\t grad: 1 2 -2.8e-05\n",
      "\t grad: 2 4 -0.00011\n",
      "\t grad: 3 6 -0.000227\n",
      "\t grad: 1 2 -2.1e-05\n",
      "\t grad: 2 4 -8.1e-05\n",
      "\t grad: 3 6 -0.000168\n",
      "\t grad: 1 2 -1.5e-05\n",
      "\t grad: 2 4 -6e-05\n",
      "\t grad: 3 6 -0.000124\n",
      "\t grad: 1 2 -1.1e-05\n",
      "\t grad: 2 4 -4.4e-05\n",
      "\t grad: 3 6 -9.2e-05\n",
      "progress: 40 w = 2.0 loss = 0.0\n",
      "\t grad: 1 2 -8e-06\n",
      "\t grad: 2 4 -3.3e-05\n",
      "\t grad: 3 6 -6.8e-05\n",
      "\t grad: 1 2 -6e-06\n",
      "\t grad: 2 4 -2.4e-05\n",
      "\t grad: 3 6 -5e-05\n",
      "\t grad: 1 2 -5e-06\n",
      "\t grad: 2 4 -1.8e-05\n",
      "\t grad: 3 6 -3.7e-05\n",
      "\t grad: 1 2 -3e-06\n",
      "\t grad: 2 4 -1.3e-05\n",
      "\t grad: 3 6 -2.7e-05\n",
      "\t grad: 1 2 -3e-06\n",
      "\t grad: 2 4 -1e-05\n",
      "\t grad: 3 6 -2e-05\n",
      "\t grad: 1 2 -2e-06\n",
      "\t grad: 2 4 -7e-06\n",
      "\t grad: 3 6 -1.5e-05\n",
      "\t grad: 1 2 -1e-06\n",
      "\t grad: 2 4 -5e-06\n",
      "\t grad: 3 6 -1.1e-05\n",
      "\t grad: 1 2 -1e-06\n",
      "\t grad: 2 4 -4e-06\n",
      "\t grad: 3 6 -8e-06\n",
      "\t grad: 1 2 -1e-06\n",
      "\t grad: 2 4 -3e-06\n",
      "\t grad: 3 6 -6e-06\n",
      "predict (after training) 4 hours 7.999998894782476\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [2, 4, 6]\n",
    "\n",
    "w = 1.0  # a random guess (i.e. random value)\n",
    "\n",
    "# a lineadr model for the forward pass\n",
    "def forward(x):\n",
    "    return x * w\n",
    "\n",
    "# Loss function\n",
    "def loss(x, y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y) * (y_pred - y)\n",
    "\n",
    "def gradient(x, y):\n",
    "    return 2 * x * (x * w - y)\n",
    "\n",
    "for epoch in range(50):\n",
    "    for x, y in zip(x_data, y_data):\n",
    "        grad = gradient(x, y)\n",
    "        w = w - 0.01 * grad\n",
    "        print('\\t grad:', x, y, round(grad, 6))\n",
    "        l = loss(x, y)\n",
    "    if (epoch%10 == 0) :    \n",
    "        print(\"progress:\", epoch, \"w =\", round(w,2), \"loss =\", round(l,6))\n",
    "        \n",
    "print(\"predict (after training)\", \"4 hours\", forward(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1 : Compute gradient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\hat{y} = x^2w_2 + xw_1 + b $$\n",
    "\n",
    "$$ \\text{loss} = (\\hat{y} - y)^2 = (x^2w_2 + xw_1 + b - y)^2 $$\n",
    "\n",
    "$$ {\\partial \\text{loss} \\over \\partial w_1 } =  2x(x^2w_2 + xw_1 + b - y)$$\n",
    "\n",
    "$$ {\\partial \\text{loss} \\over \\partial w_2 } = ? $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2 : implement\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
